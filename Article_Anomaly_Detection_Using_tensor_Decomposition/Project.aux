\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\Newlabel{cor1}{1}
\citation{rcglobal2021}
\citation{patcha2007overview}
\citation{eren2023general}
\citation{hilton2016dyn}
\citation{paloaltonetworks2024}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{Project.ist}
\@glsorder{word}
\Newlabel{label1}{a}
\Newlabel{label2}{b}
\Newlabel{label3}{c}
\Newlabel{label4}{d}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{biau2016randomforest}
\citation{marukatat2022tutorial}
\citation{lee2000nmf}
\citation{Su2025Robust}
\citation{kolda2009tensor}
\citation{ranjbar2018qanet}
\citation{bruns2016ensign}
\citation{xie2018graph}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{3}{section.2}\protected@file@percent }
\citation{jafarigiv2023tensor}
\citation{most2023electrical}
\citation{zhang2019hybrid}
\citation{sun2006incremental}
\citation{sun2006beyond}
\citation{eren2023general}
\citation{streit2021network}
\citation{wu2021graph}
\citation{kruskal1977three,kolda2009tensor}
\citation{rabbani2024iot-diad}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data and Methodology}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset}{5}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the proposed framework : This figure outlines the }}{6}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{6}{Overview of the proposed framework : This figure outlines the}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Tensor Construction}{7}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces CIC Tensor at Time Window $t$: This figure shows the CIC IoT 2024 tensor at a given time window. Black points represent benign traffic, while orange points indicate malicious traffic. The tensor is structured in three dimensions: source, destination, and feature.}}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:tensor_3d}{{2}{8}{CIC Tensor at Time Window $t$: This figure shows the CIC IoT 2024 tensor at a given time window. Black points represent benign traffic, while orange points indicate malicious traffic. The tensor is structured in three dimensions: source, destination, and feature}{figure.caption.2}{}}
\citation{kruskal1977three}
\citation{kruskal1977three}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}CP Tensor Decomposition}{9}{subsection.3.3}\protected@file@percent }
\newlabel{eq:cp-basic}{{2}{9}{CP Tensor Decomposition}{equation.2}{}}
\newlabel{eq:cp-lambda}{{3}{9}{CP Tensor Decomposition}{equation.3}{}}
\newlabel{eq:kruskal-form}{{4}{9}{CP Tensor Decomposition}{equation.4}{}}
\newlabel{eq:mode_n_unfolding}{{5}{9}{CP Tensor Decomposition}{equation.5}{}}
\citation{kruskal1977three}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces CP Decomposition using ALS }}{10}{algocf.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Normal space Projection}{11}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Enhanced multi-perspective aggregation}{11}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Deep learning classifiers and evaluations}{12}{subsection.3.6}\protected@file@percent }
\citation{ding2019acnet}
\citation{tensorflow_addons2021}
\citation{li2019understanding}
\citation{labach2019survey,rippel2015spectral}
\citation{ioffe2015batch}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Deep learning architecture used our the experimentation. It exhibits the order Activation (ReLU) $\rightarrow $ Batch Normalization (BN) $\rightarrow $ Dropout }}{13}{figure.caption.3}\protected@file@percent }
\newlabel{Deeplearning}{{3}{13}{Deep learning architecture used our the experimentation. It exhibits the order Activation (ReLU) $\rightarrow $ Batch Normalization (BN) $\rightarrow $ Dropout}{figure.caption.3}{}}
\citation{kun2016accurate}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{14}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Network Traffic Behaviour Extraction}{14}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Compression Graph showing reconstruction error vs. rank. It shows the improvement quality of the decomposition}}{15}{figure.caption.4}\protected@file@percent }
\newlabel{fig:Compression graph}{{4}{15}{Compression Graph showing reconstruction error vs. rank. It shows the improvement quality of the decomposition}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Temporal Behaviour of CIC-IoT 2024 Normal Traffic: Each colour in the figure represents a temporal mode obtained from the decomposition of the normal traffic tensor for a specific rank ranging from $1$ to $16$, illustrating the evolution of temporal patterns across successive time windows.}}{16}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Temporal_features}{{5}{16}{Temporal Behaviour of CIC-IoT 2024 Normal Traffic: Each colour in the figure represents a temporal mode obtained from the decomposition of the normal traffic tensor for a specific rank ranging from $1$ to $16$, illustrating the evolution of temporal patterns across successive time windows}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Source IP Address Behaviour in CIC IoT 2024 Normal Traffic Tensor. This figure illustrates the source IP factor components extracted from tensor decomposition at different ranks, demonstrating how source IP addresses contribute to normal traffic patterns. Each colour represents a distinct component corresponding to a different rank value.}}{17}{figure.caption.6}\protected@file@percent }
\newlabel{fig:source_IP}{{6}{17}{Source IP Address Behaviour in CIC IoT 2024 Normal Traffic Tensor. This figure illustrates the source IP factor components extracted from tensor decomposition at different ranks, demonstrating how source IP addresses contribute to normal traffic patterns. Each colour represents a distinct component corresponding to a different rank value}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Destination IP Address Behaviour in the CIC IoT 2024 Normal Traffic Tensor: This figure shows the destination IP address factors for each rank of the tensor decomposition. Each colour represents a specific rank and illustrates how the destination IP addresses contribute to the normal traffic behaviour.}}{17}{figure.caption.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Features Behaviour in CIC IoT 2024 Traffic: This figure shows how the magnitude of features varies across latent factors for each rank considered in the tensor decomposition. Each component is represented by a different colour.}}{18}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ranks_evolution}{{8}{18}{Features Behaviour in CIC IoT 2024 Traffic: This figure shows how the magnitude of features varies across latent factors for each rank considered in the tensor decomposition. Each component is represented by a different colour}{figure.caption.8}{}}
\newlabel{fig:train-error}{{9a}{19}{Training projection norm across different tensor ranks}{figure.caption.9}{}}
\newlabel{sub@fig:train-error}{{a}{19}{Training projection norm across different tensor ranks}{figure.caption.9}{}}
\newlabel{fig:test-error}{{9b}{19}{Test projection norm across different tensor ranks}{figure.caption.9}{}}
\newlabel{sub@fig:test-error}{{b}{19}{Test projection norm across different tensor ranks}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Projection Norms Across Different Tensor Ranks for the Train and Test Tensors: This figure illustrates the projection norms into the normal latent space for both the training and testing tensors across different ranks, highlighting how the choice of rank affects the representation of the latent space.}}{19}{figure.caption.9}\protected@file@percent }
\newlabel{fig:projection-norms}{{9}{19}{Projection Norms Across Different Tensor Ranks for the Train and Test Tensors: This figure illustrates the projection norms into the normal latent space for both the training and testing tensors across different ranks, highlighting how the choice of rank affects the representation of the latent space}{figure.caption.9}{}}
\newlabel{fig:train-residuals}{{10a}{20}{Training Projection Error across different tensor ranks}{figure.caption.10}{}}
\newlabel{sub@fig:train-residuals}{{a}{20}{Training Projection Error across different tensor ranks}{figure.caption.10}{}}
\newlabel{fig:test-residuals}{{10b}{20}{Testing Projection Error across different tensor ranks}{figure.caption.10}{}}
\newlabel{sub@fig:test-residuals}{{b}{20}{Testing Projection Error across different tensor ranks}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Projection Error for Train and Test Tensors Across Different Tensor Ranks (Scale $10^{-1}$): This figure illustrates the projection error for both the training and testing tensors across different ranks, showing how the choice of rank affects the reconstruction error in the latent space.}}{20}{figure.caption.10}\protected@file@percent }
\newlabel{fig:train-test-residual}{{10}{20}{Projection Error for Train and Test Tensors Across Different Tensor Ranks (Scale $10^{-1}$): This figure illustrates the projection error for both the training and testing tensors across different ranks, showing how the choice of rank affects the reconstruction error in the latent space}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Anomaly Detection And Rank selection Results}{20}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion Matrices for Tensor Ranks 1–3: This figure presents the confusion matrices for tensor ranks 1 to 3, illustrating the classification performance of the models for each rank.}}{20}{figure.caption.11}\protected@file@percent }
\newlabel{fig:confusion_matrices_1}{{11}{20}{Confusion Matrices for Tensor Ranks 1–3: This figure presents the confusion matrices for tensor ranks 1 to 3, illustrating the classification performance of the models for each rank}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Confusion matrices for tensor ranks 4–12, showing the classification performance of the models for each rank.}}{21}{figure.caption.12}\protected@file@percent }
\newlabel{fig:confusion_matrices_2}{{12}{21}{Confusion matrices for tensor ranks 4–12, showing the classification performance of the models for each rank}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Confusion Matrices for Tensor Ranks 13–16: This figure presents the confusion matrices for tensor ranks 13 to 16, illustrating the classification performance of the models for each rank.}}{22}{figure.caption.13}\protected@file@percent }
\newlabel{fig:confusion_matrices_3}{{13}{22}{Confusion Matrices for Tensor Ranks 13–16: This figure presents the confusion matrices for tensor ranks 13 to 16, illustrating the classification performance of the models for each rank}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Accuracy of each model: This figure illustrates the accuracy scores obtained by each trained model. It provides an overall view of how well each model classifies both normal and anomalous traffic, highlighting the rank that yields the highest predictive performance.}}{23}{figure.caption.14}\protected@file@percent }
\newlabel{fig:accl}{{14}{23}{Accuracy of each model: This figure illustrates the accuracy scores obtained by each trained model. It provides an overall view of how well each model classifies both normal and anomalous traffic, highlighting the rank that yields the highest predictive performance}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Recall of each model: This figure presents the recall achieved by each trained model. It highlights the models’ ability to correctly identify anomalous traffic, emphasising which rank provides the most reliable detection performance.}}{24}{figure.caption.15}\protected@file@percent }
\newlabel{fig:recall}{{15}{24}{Recall of each model: This figure presents the recall achieved by each trained model. It highlights the models’ ability to correctly identify anomalous traffic, emphasising which rank provides the most reliable detection performance}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces F1-scores of each model: This figure illustrates the F1-score obtained for each trained model. It highlights the variation in performance and identifies the rank that yields the best balance between precision and recall.}}{24}{figure.caption.16}\protected@file@percent }
\newlabel{fig:f1}{{16}{24}{F1-scores of each model: This figure illustrates the F1-score obtained for each trained model. It highlights the variation in performance and identifies the rank that yields the best balance between precision and recall}{figure.caption.16}{}}
\citation{eren2023general}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Models performance summary table: This table summarises the performance of each trained model. It reports the accuracy, recall, and F1-score of each model, and highlights Model 9 as the best-performing one. }}{25}{table.caption.17}\protected@file@percent }
\newlabel{tab:model_comparison}{{1}{25}{Models performance summary table: This table summarises the performance of each trained model. It reports the accuracy, recall, and F1-score of each model, and highlights Model 9 as the best-performing one}{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with the state-of-the-art}{26}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Confusion matrices of Decision Tree and Random Forest: This figure shows the performance of both models in classifying normal and anomalous traffic.}}{26}{figure.caption.18}\protected@file@percent }
\newlabel{fig:confusion_matrices_tree_forest}{{17}{26}{Confusion matrices of Decision Tree and Random Forest: This figure shows the performance of both models in classifying normal and anomalous traffic}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Confusion Matrices of Support Vector Machine and LSTM: This figure illustrates the performance of both models in classifying normal and anomalous traffic.}}{27}{figure.caption.19}\protected@file@percent }
\newlabel{fig:confusion_matrices_svm_lstm}{{18}{27}{Confusion Matrices of Support Vector Machine and LSTM: This figure illustrates the performance of both models in classifying normal and anomalous traffic}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces False Positive and False Negative Rates Across Classification Models: This figure summarizes the comparison between our model and state-of-the-art approaches in terms of false positives and false negatives. False positives are represented by the red bands, while false negatives are shown in blue. The results highlight how our method outperforms traditional approaches.}}{28}{figure.caption.20}\protected@file@percent }
\newlabel{fig:fp_fn_comparison}{{19}{28}{False Positive and False Negative Rates Across Classification Models: This figure summarizes the comparison between our model and state-of-the-art approaches in terms of false positives and false negatives. False positives are represented by the red bands, while false negatives are shown in blue. The results highlight how our method outperforms traditional approaches}{figure.caption.20}{}}
\citation{streit2021network}
\citation{limitation2023generalization}
\citation{al2021machine}
\citation{streit2021network}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Conclusion}{31}{subsection.4.4}\protected@file@percent }
\bibstyle{elsarticle-harv}
\bibdata{References}
\@writefile{toc}{\contentsline {section}{\numberline {5}CRediT authorship contribution statement}{32}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Data availability}{32}{section.6}\protected@file@percent }
\bibcite{al2021machine}{{1}{2021}{{Al-Habashna and Alqahtani}}{{}}}
\bibcite{biau2016randomforest}{{2}{2016}{{Biau and Scornet}}{{}}}
\bibcite{bruns2016ensign}{{3}{2015}{{Bruns-Smith et~al.}}{{Bruns-Smith, Baskaran, Ezick, Henretty and Lethin}}}
\bibcite{ding2019acnet}{{4}{2019}{{Ding et~al.}}{{Ding, Guo, Ding and Han}}}
\bibcite{eren2023general}{{5}{2023}{{Eren et~al.}}{{Eren, Moore, Skau, Moore, Bhattarai, Chennupati and Alexandrov}}}
\bibcite{rcglobal2021}{{6}{2021}{{FM}}{{}}}
\bibcite{hilton2016dyn}{{7}{2016}{{Hilton}}{{}}}
\bibcite{ioffe2015batch}{{8}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{jafarigiv2023tensor}{{9}{2023}{{Jafarigiv et~al.}}{{Jafarigiv, Sheshyekani and Kassouf}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Acknowledgements}{33}{section.7}\protected@file@percent }
\bibcite{kolda2009tensor}{{10}{2009}{{Kolda and Bader}}{{}}}
\bibcite{kruskal1977three}{{11}{1977}{{Kruskal}}{{}}}
\bibcite{limitation2023generalization}{{12}{2023}{{Kumar et~al.}}{{Kumar, Patel and Robinson}}}
\bibcite{labach2019survey}{{13}{2019}{{Labach et~al.}}{{Labach, Salehinejad and Valaee}}}
\bibcite{lee2000nmf}{{14}{2000}{{Lee and Seung}}{{}}}
\bibcite{li2019understanding}{{15}{2019}{{Li et~al.}}{{Li, Chen, Hu and Yang}}}
\bibcite{marukatat2022tutorial}{{16}{2022}{{Marukatat}}{{}}}
\bibcite{most2023electrical}{{17}{2023}{{Most et~al.}}{{Most, Eren, Alexandrov and Lawrence}}}
\bibcite{paloaltonetworks2024}{{18}{2024}{{Palo Alto Networks}}{{}}}
\bibcite{patcha2007overview}{{19}{2007}{{Patcha and Park}}{{}}}
\bibcite{rabbani2024iot-diad}{{20}{2024}{{Rabbani et~al.}}{{Rabbani, Gui, Nejati, Zhou, Kaniyamattam, Mirani, Piya, Opushnyev, Lu and Ghorbani}}}
\bibcite{ranjbar2018qanet}{{21}{2018}{{Ranjbar et~al.}}{{Ranjbar, Salehi, Jandaghi and Jalili}}}
\bibcite{rippel2015spectral}{{22}{2015}{{Rippel et~al.}}{{Rippel, Snoek and Adams}}}
\bibcite{streit2021network}{{23}{2021}{{Streit et~al.}}{{Streit, Santos, Leão, de~Souza~e Silva, Menasché and Towsley}}}
\bibcite{Su2025Robust}{{24}{2025}{{Su}}{{}}}
\bibcite{sun2006beyond}{{25}{2006a}{{Sun et~al.}}{{Sun, Papadimitriou and Yu}}}
\bibcite{sun2006incremental}{{26}{2006b}{{Sun et~al.}}{{Sun, Tao and Faloutsos}}}
\bibcite{tensorflow_addons2021}{{27}{2021}{{TensorFlow Addons Maintainers}}{{}}}
\bibcite{wu2021graph}{{28}{2021}{{Wu et~al.}}{{Wu, Pan, Chen, Long, Zhang and Yu}}}
\bibcite{xie2018graph}{{29}{2018}{{Xie et~al.}}{{Xie, Li, Wang, Xie, Wen and Zhang}}}
\bibcite{kun2016accurate}{{30}{2016}{{Xie et~al.}}{{Xie, Wang, Wang and Wen}}}
\bibcite{zhang2019hybrid}{{31}{2019}{{Zhang et~al.}}{{Zhang, Yu and Zhou}}}
\gdef \@abspage@last{36}
