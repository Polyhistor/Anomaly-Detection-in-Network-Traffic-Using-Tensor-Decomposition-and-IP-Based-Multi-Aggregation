\relax 
\bibstyle{sn-mathphys-num}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\Newlabel{1}{1}
\Newlabel{2}{2}
\Newlabel{3}{3}
\Newlabel{4}{4}
\citation{rcglobal2021}
\citation{patcha2007overview}
\citation{eren2023general}
\citation{hilton2016dyn}
\citation{paloaltonetworks2024}
\citation{biau2016randomforest}
\citation{marukatat2022tutorial}
\citation{lee2000nmf}
\citation{Su2025Robust}
\citation{kolda2009tensor}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\citation{ranjbar2018qanet}
\citation{bruns2016ensign}
\citation{xie2018graph}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{3}{section.2}\protected@file@percent }
\citation{jafarigiv2023tensor}
\citation{most2023electrical}
\citation{zhang2019hybrid}
\citation{sun2006incremental}
\citation{sun2006beyond}
\citation{eren2023general}
\citation{streit2021network}
\citation{wu2021graph}
\citation{kruskal1977three,kolda2009tensor}
\citation{rabbani2024iot-diad}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data and Methodology}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset}{5}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the proposed framework : This figure outlines the }}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{6}{Overview of the proposed framework : This figure outlines the}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Tensor Construction}{7}{subsection.3.2}\protected@file@percent }
\citation{kruskal1977three}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces CIC Tensor at Time Window $t$: This figure shows the CIC IoT 2024 tensor at a given time window. Black points represent benign traffic, while orange points indicate malicious traffic. The tensor is structured in three dimensions: source, destination, and feature.}}{8}{figure.caption.3}\protected@file@percent }
\newlabel{fig:tensor_3d}{{2}{8}{CIC Tensor at Time Window $t$: This figure shows the CIC IoT 2024 tensor at a given time window. Black points represent benign traffic, while orange points indicate malicious traffic. The tensor is structured in three dimensions: source, destination, and feature}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}CP Tensor Decomposition}{8}{subsection.3.3}\protected@file@percent }
\newlabel{eq:cp-basic}{{2}{8}{CP Tensor Decomposition}{equation.2}{}}
\newlabel{eq:cp-lambda}{{3}{8}{CP Tensor Decomposition}{equation.3}{}}
\newlabel{eq:kruskal-form}{{4}{8}{CP Tensor Decomposition}{equation.4}{}}
\citation{kruskal1977three}
\citation{kruskal1977three}
\newlabel{eq:mode_n_unfolding}{{5}{9}{CP Tensor Decomposition}{equation.5}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces CP Decomposition using ALS }}{10}{algocf.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Normal space Projection}{10}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Enhanced multi-perspective aggregation}{11}{subsection.3.5}\protected@file@percent }
\citation{ding2019acnet}
\citation{tensorflow_addons2021}
\citation{li2019understanding}
\citation{labach2019survey,rippel2015spectral}
\citation{ioffe2015batch}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Deep learning classifiers and evaluations}{12}{subsection.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Deep learning architecture used our the experimentation. It exhibits the order Activation (ReLU) $\rightarrow $ Batch Normalization (BN) $\rightarrow $ Dropout }}{12}{figure.caption.4}\protected@file@percent }
\newlabel{Deeplearning}{{3}{12}{Deep learning architecture used our the experimentation. It exhibits the order Activation (ReLU) $\rightarrow $ Batch Normalization (BN) $\rightarrow $ Dropout}{figure.caption.4}{}}
\citation{kun2016accurate}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Network Traffic Behaviour Extraction}{13}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Compression Graph showing reconstruction error vs. rank. It shows the improvement quality of the decomposition}}{14}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Compression graph}{{4}{14}{Compression Graph showing reconstruction error vs. rank. It shows the improvement quality of the decomposition}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Temporal Behaviour of CIC-IoT 2024 Normal Traffic: Each colour in the figure represents a temporal mode obtained from the decomposition of the normal traffic tensor for a specific rank ranging from $1$ to $16$, illustrating the evolution of temporal patterns across successive time windows.}}{15}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Temporal_features}{{5}{15}{Temporal Behaviour of CIC-IoT 2024 Normal Traffic: Each colour in the figure represents a temporal mode obtained from the decomposition of the normal traffic tensor for a specific rank ranging from $1$ to $16$, illustrating the evolution of temporal patterns across successive time windows}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Source IP Address Behaviour in CIC IoT 2024 Normal Traffic Tensor. This figure illustrates the source IP factor components extracted from tensor decomposition at different ranks, demonstrating how source IP addresses contribute to normal traffic patterns. Each colour represents a distinct component corresponding to a different rank value.}}{16}{figure.caption.7}\protected@file@percent }
\newlabel{fig:source_IP}{{6}{16}{Source IP Address Behaviour in CIC IoT 2024 Normal Traffic Tensor. This figure illustrates the source IP factor components extracted from tensor decomposition at different ranks, demonstrating how source IP addresses contribute to normal traffic patterns. Each colour represents a distinct component corresponding to a different rank value}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Destination IP Address Behaviour in the CIC IoT 2024 Normal Traffic Tensor: This figure shows the destination IP address factors for each rank of the tensor decomposition. Each colour represents a specific rank and illustrates how the destination IP addresses contribute to the normal traffic behaviour.}}{16}{figure.caption.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Features Behaviour in CIC IoT 2024 Traffic: This figure shows how the magnitude of features varies across latent factors for each rank considered in the tensor decomposition. Each component is represented by a different colour.}}{17}{figure.caption.9}\protected@file@percent }
\newlabel{fig:ranks_evolution}{{8}{17}{Features Behaviour in CIC IoT 2024 Traffic: This figure shows how the magnitude of features varies across latent factors for each rank considered in the tensor decomposition. Each component is represented by a different colour}{figure.caption.9}{}}
\newlabel{fig:train-error}{{9a}{18}{Training projection norm across different tensor ranks}{figure.caption.10}{}}
\newlabel{sub@fig:train-error}{{a}{18}{Training projection norm across different tensor ranks}{figure.caption.10}{}}
\newlabel{fig:test-error}{{9b}{18}{Test projection norm across different tensor ranks}{figure.caption.10}{}}
\newlabel{sub@fig:test-error}{{b}{18}{Test projection norm across different tensor ranks}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Projection Norms Across Different Tensor Ranks for the Train and Test Tensors: This figure illustrates the projection norms into the normal latent space for both the training and testing tensors across different ranks, highlighting how the choice of rank affects the representation of the latent space.}}{18}{figure.caption.10}\protected@file@percent }
\newlabel{fig:projection-norms}{{9}{18}{Projection Norms Across Different Tensor Ranks for the Train and Test Tensors: This figure illustrates the projection norms into the normal latent space for both the training and testing tensors across different ranks, highlighting how the choice of rank affects the representation of the latent space}{figure.caption.10}{}}
\newlabel{fig:train-residuals}{{10a}{19}{Training Projection Error across different tensor ranks}{figure.caption.11}{}}
\newlabel{sub@fig:train-residuals}{{a}{19}{Training Projection Error across different tensor ranks}{figure.caption.11}{}}
\newlabel{fig:test-residuals}{{10b}{19}{Testing Projection Error across different tensor ranks}{figure.caption.11}{}}
\newlabel{sub@fig:test-residuals}{{b}{19}{Testing Projection Error across different tensor ranks}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Projection Error for Train and Test Tensors Across Different Tensor Ranks (Scale $10^{-1}$): This figure illustrates the projection error for both the training and testing tensors across different ranks, showing how the choice of rank affects the reconstruction error in the latent space.}}{19}{figure.caption.11}\protected@file@percent }
\newlabel{fig:train-test-residual}{{10}{19}{Projection Error for Train and Test Tensors Across Different Tensor Ranks (Scale $10^{-1}$): This figure illustrates the projection error for both the training and testing tensors across different ranks, showing how the choice of rank affects the reconstruction error in the latent space}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Anomaly Detection And Rank selection Results}{19}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Confusion Matrices for Tensor Ranks 1–3: This figure presents the confusion matrices for tensor ranks 1 to 3, illustrating the classification performance of the models for each rank.}}{19}{figure.caption.12}\protected@file@percent }
\newlabel{fig:confusion_matrices_1}{{11}{19}{Confusion Matrices for Tensor Ranks 1–3: This figure presents the confusion matrices for tensor ranks 1 to 3, illustrating the classification performance of the models for each rank}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Confusion matrices for tensor ranks 4–12, showing the classification performance of the models for each rank.}}{20}{figure.caption.13}\protected@file@percent }
\newlabel{fig:confusion_matrices_2}{{12}{20}{Confusion matrices for tensor ranks 4–12, showing the classification performance of the models for each rank}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Confusion Matrices for Tensor Ranks 13–16: This figure presents the confusion matrices for tensor ranks 13 to 16, illustrating the classification performance of the models for each rank.}}{21}{figure.caption.14}\protected@file@percent }
\newlabel{fig:confusion_matrices_3}{{13}{21}{Confusion Matrices for Tensor Ranks 13–16: This figure presents the confusion matrices for tensor ranks 13 to 16, illustrating the classification performance of the models for each rank}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Accuracy of each model: This figure illustrates the accuracy scores obtained by each trained model. It provides an overall view of how well each model classifies both normal and anomalous traffic, highlighting the rank that yields the highest predictive performance.}}{22}{figure.caption.15}\protected@file@percent }
\newlabel{fig:accl}{{14}{22}{Accuracy of each model: This figure illustrates the accuracy scores obtained by each trained model. It provides an overall view of how well each model classifies both normal and anomalous traffic, highlighting the rank that yields the highest predictive performance}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Recall of each model: This figure presents the recall achieved by each trained model. It highlights the models’ ability to correctly identify anomalous traffic, emphasising which rank provides the most reliable detection performance.}}{22}{figure.caption.16}\protected@file@percent }
\newlabel{fig:recall}{{15}{22}{Recall of each model: This figure presents the recall achieved by each trained model. It highlights the models’ ability to correctly identify anomalous traffic, emphasising which rank provides the most reliable detection performance}{figure.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Models performance summary table: This table summarises the performance of each trained model. It reports the accuracy, recall, and F1-score of each model, and highlights Model 9 as the best-performing one.}}{23}{table.caption.19}\protected@file@percent }
\newlabel{tab:model_comparison}{{1}{23}{Models performance summary table: This table summarises the performance of each trained model. It reports the accuracy, recall, and F1-score of each model, and highlights Model 9 as the best-performing one}{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces F1-scores of each model: This figure illustrates the F1-score obtained for each trained model. It highlights the variation in performance and identifies the rank that yields the best balance between precision and recall.}}{23}{figure.caption.17}\protected@file@percent }
\newlabel{fig:f1}{{16}{23}{F1-scores of each model: This figure illustrates the F1-score obtained for each trained model. It highlights the variation in performance and identifies the rank that yields the best balance between precision and recall}{figure.caption.17}{}}
\citation{eren2023general}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with the state-of-the-art}{24}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Confusion matrices of Decision Tree and Random Forest: This figure shows the performance of both models in classifying normal and anomalous traffic.}}{24}{figure.caption.20}\protected@file@percent }
\newlabel{fig:confusion_matrices_tree_forest}{{17}{24}{Confusion matrices of Decision Tree and Random Forest: This figure shows the performance of both models in classifying normal and anomalous traffic}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Confusion Matrices of Support Vector Machine and LSTM: This figure illustrates the performance of both models in classifying normal and anomalous traffic.}}{25}{figure.caption.21}\protected@file@percent }
\newlabel{fig:confusion_matrices_svm_lstm}{{18}{25}{Confusion Matrices of Support Vector Machine and LSTM: This figure illustrates the performance of both models in classifying normal and anomalous traffic}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces False Positive and False Negative Rates Across Classification Models: This figure summarizes the comparison between our model and state-of-the-art approaches in terms of false positives and false negatives. False positives are represented by the red bands, while false negatives are shown in blue. The results highlight how our method outperforms traditional approaches.}}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig:fp_fn_comparison}{{19}{25}{False Positive and False Negative Rates Across Classification Models: This figure summarizes the comparison between our model and state-of-the-art approaches in terms of false positives and false negatives. False positives are represented by the red bands, while false negatives are shown in blue. The results highlight how our method outperforms traditional approaches}{figure.caption.22}{}}
\citation{streit2021network}
\citation{limitation2023generalization}
\citation{al2021machine}
\citation{streit2021network}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{28}{section.5}\protected@file@percent }
\bibdata{References}
\bibcite{rcglobal2021}{{1}{2021}{{FM}}{{}}}
\@writefile{toc}{\contentsline {subparagraph}{Acknowledgements}{29}{section*.23}\protected@file@percent }
\bibcite{patcha2007overview}{{2}{2007}{{Patcha and Park}}{{}}}
\bibcite{eren2023general}{{3}{2023}{{Eren et~al.}}{{}}}
\bibcite{hilton2016dyn}{{4}{2016}{{Hilton}}{{}}}
\bibcite{paloaltonetworks2024}{{5}{2024}{{{Palo Alto Networks}}}{{}}}
\bibcite{biau2016randomforest}{{6}{2016}{{Biau and Scornet}}{{}}}
\bibcite{marukatat2022tutorial}{{7}{2022}{{Marukatat}}{{}}}
\bibcite{lee2000nmf}{{8}{2000}{{Lee and Seung}}{{}}}
\bibcite{Su2025Robust}{{9}{2025}{{Su}}{{}}}
\bibcite{kolda2009tensor}{{10}{2009}{{Kolda and Bader}}{{}}}
\bibcite{ranjbar2018qanet}{{11}{2018}{{Ranjbar et~al.}}{{}}}
\bibcite{bruns2016ensign}{{12}{2015}{{Bruns-Smith et~al.}}{{}}}
\bibcite{xie2018graph}{{13}{2018}{{Xie et~al.}}{{}}}
\bibcite{jafarigiv2023tensor}{{14}{2023}{{Jafarigiv et~al.}}{{}}}
\bibcite{most2023electrical}{{15}{2023}{{Most et~al.}}{{}}}
\bibcite{zhang2019hybrid}{{16}{2019}{{Zhang et~al.}}{{}}}
\bibcite{sun2006incremental}{{17}{2006a}{{Sun et~al.}}{{}}}
\bibcite{sun2006beyond}{{18}{2006b}{{Sun et~al.}}{{}}}
\bibcite{streit2021network}{{19}{2021}{{Streit et~al.}}{{}}}
\bibcite{wu2021graph}{{20}{2021}{{Wu et~al.}}{{}}}
\bibcite{kruskal1977three}{{21}{1977}{{Kruskal}}{{}}}
\bibcite{rabbani2024iot-diad}{{22}{2024}{{Rabbani et~al.}}{{}}}
\bibcite{ding2019acnet}{{23}{2019}{{Ding et~al.}}{{}}}
\bibcite{tensorflow_addons2021}{{24}{2021}{{{TensorFlow Addons Maintainers}}}{{}}}
\bibcite{li2019understanding}{{25}{2019}{{Li et~al.}}{{}}}
\bibcite{labach2019survey}{{26}{2019}{{Labach et~al.}}{{}}}
\bibcite{rippel2015spectral}{{27}{2015}{{Rippel et~al.}}{{}}}
\bibcite{ioffe2015batch}{{28}{2015}{{Ioffe and Szegedy}}{{}}}
\bibcite{kun2016accurate}{{29}{2016}{{Xie et~al.}}{{}}}
\bibcite{limitation2023generalization}{{30}{2023}{{Kumar et~al.}}{{}}}
\bibcite{al2021machine}{{31}{2021}{{Al-Habashna and Alqahtani}}{{}}}
\gdef \@abspage@last{32}
